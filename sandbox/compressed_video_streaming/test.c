#include <ffmpeg/avcodec.h>
#include <ffmpeg/avformat.h>
#include <ffmpeg/swscale.h>

#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>


int read_data(void *opaque, uint8_t *buf, int buf_size) {
	// first read from file, until ffmpeg works
	// (later try to receive data from network)
	FILE * fp = (FILE *) opaque;
	if (!fp) {
		return -1;
	}

	int cnt = fread(buf, sizeof(uint8_t), buf_size, fp);
	return cnt;
}

static void SaveFrame(AVFrame *pFrame, int width, int height, int iFrame)
{
    FILE *pFile;
    char szFilename[32];
    int  y;

    // Open file
    sprintf(szFilename, "frame%d.ppm", iFrame);
    pFile=fopen(szFilename, "wb");
    if(pFile==NULL)
        return;

    // Write header
    fprintf(pFile, "P6\n%d %d\n255\n", width, height);

    // Write pixel data
    for(y=0; y<height; y++)
        fwrite(pFrame->data[0]+y*pFrame->linesize[0], 1, width*3, pFile);

    // Close file
    fclose(pFile);
}

int main(int argc, const char * argv[]) {

	AVFormatContext *pFormatCtx;
	int i, videoStream;
	AVCodecContext *pCodecCtx;
	AVCodec *pCodec;
	AVFrame *pFrame;
	AVFrame         *pFrameRGB;
	AVPacket packet;
	int frameFinished;
	int buffer_current_pos;
	int             numBytes;
	uint8_t         *buffer;

	printf("Argv0: %s, Argv1: %s\n", argv[0], argv[1]);

	FILE * fp = fopen(argv[1], "r");
	if(fp==0)
	{
		printf("Error5!\n");
		return 5;
	}

	// Register all formats and codecs
	av_register_all();

	uint8_t* pDataBuffer = malloc(20000000);
	long lSize = 20000000;

	lSize = read_data(fp, pDataBuffer, lSize);

	printf("Read %d bytes.\n", lSize);

	AVProbeData pd;
	pd.buf = pDataBuffer;
	pd.buf_size = lSize;
	pd.filename = "";

	AVInputFormat* pAVInputFormat = av_probe_input_format(&pd, 1);
	if (!pAVInputFormat) {
		printf("Error1!\n");
		return 1;
	}
	pAVInputFormat->flags |= AVFMT_NOFILE;

	ByteIOContext ByteIOCtx;
	if (init_put_byte(&ByteIOCtx, pDataBuffer, lSize, 0, fp, read_data, NULL,
			NULL) < 0) {
		printf("Error2!\n");
		return 2;
	}

	if (av_open_input_stream(&pFormatCtx, &ByteIOCtx, "", pAVInputFormat, NULL)
			< 0) {
		printf("Error3!\n");
		return 3;
	}

	if (av_find_stream_info(pFormatCtx) < 0) {
		printf("Error4 Format!!\n");
		return 4;
	}

	// Dump information about file onto standard error
	dump_format(pFormatCtx, 0, /*argv[1]*/ "HeyHey", 0);

	// Find the first video stream
	videoStream = -1;
	for (i = 0; i < pFormatCtx->nb_streams; i++) {
		if (pFormatCtx->streams[i]->codec->codec_type == CODEC_TYPE_VIDEO) {
			videoStream = i;
			break;
		}
	}

	if (videoStream == -1) {
		fprintf(stderr, "didn't find a video stream\n");
		return 0; // Didn't find a video stream
	}

	// Get a pointer to the codec context for the video stream
	    pCodecCtx=pFormatCtx->streams[videoStream]->codec;

	    // Find the decoder for the video stream
	    pCodec=avcodec_find_decoder(pCodecCtx->codec_id);
	    if(pCodec==NULL)
	        return -1; // Codec not found

	    // Open codec
	    if(avcodec_open(pCodecCtx, pCodec)<0)
	        return -1; // Could not open codec

	    // Hack to correct wrong frame rates that seem to be generated by some codecs
	    if(pCodecCtx->time_base.num>1000 && pCodecCtx->time_base.den==1)
			pCodecCtx->time_base.den=1000;

	    // Allocate video frame
	    pFrame=avcodec_alloc_frame();

	    // Allocate an AVFrame structure
	    pFrameRGB=avcodec_alloc_frame();
	    if(pFrameRGB==NULL)
	        return -1;

	    // Determine required buffer size and allocate buffer
	    numBytes=avpicture_get_size(PIX_FMT_RGB24, pCodecCtx->width,
	        pCodecCtx->height);

	    buffer=malloc(numBytes);

	    // Assign appropriate parts of buffer to image planes in pFrameRGB
	    avpicture_fill((AVPicture *)pFrameRGB, buffer, PIX_FMT_RGB24,
	        pCodecCtx->width, pCodecCtx->height);

	    // Read frames and save first five frames to disk
	    i=0;
	    while(av_read_frame(pFormatCtx, &packet)>=0)
	    {
	        // Is this a packet from the video stream?
	        if(packet.stream_index==videoStream)
	        {
	            // Decode video frame
	            avcodec_decode_video(pCodecCtx, pFrame, &frameFinished,
	                packet.data, packet.size);

	            // Did we get a video frame?
	            if(frameFinished)
	            {
					static struct SwsContext *img_convert_ctx;

	#if 0
					// Older removed code
	                // Convert the image from its native format to RGB swscale
	                img_convert((AVPicture *)pFrameRGB, PIX_FMT_RGB24,
	                    (AVPicture*)pFrame, pCodecCtx->pix_fmt, pCodecCtx->width,
	                    pCodecCtx->height);

					// function template, for reference
					int sws_scale(struct SwsContext *context, uint8_t* src[], int srcStride[], int srcSliceY,
								  int srcSliceH, uint8_t* dst[], int dstStride[]);
	#endif
					// Convert the image into YUV format that SDL uses
					if(img_convert_ctx == NULL) {
						int w = pCodecCtx->width;
						int h = pCodecCtx->height;

						img_convert_ctx = sws_getContext(w, h,
										pCodecCtx->pix_fmt,
										w, h, PIX_FMT_RGB24, SWS_BICUBIC,
										NULL, NULL, NULL);
						if(img_convert_ctx == NULL) {
							fprintf(stderr, "Cannot initialize the conversion context!\n");
							exit(1);
						}
					}
					int ret = sws_scale(img_convert_ctx, pFrame->data, pFrame->linesize, 0,
							  pCodecCtx->height, pFrameRGB->data, pFrameRGB->linesize);
	#if 0 // this use to be true, as of 1/2009, but apparently it is no longer true in 3/2009
					if(ret) {
						fprintf(stderr, "SWS_Scale failed [%d]!\n", ret);
						exit(-1);
					}
	#endif
	                // Save the frame to disk
	                if(i++<=5)
	                    SaveFrame(pFrameRGB, pCodecCtx->width, pCodecCtx->height, i);
	            }
	        }

	        // Free the packet that was allocated by av_read_frame
	        av_free_packet(&packet);
	    }

	    // Free the RGB image
	    free(buffer);
	    av_free(pFrameRGB);

	    // Free the YUV frame
	    av_free(pFrame);

	    // Close the codec
	    avcodec_close(pCodecCtx);

	    // Close the video file
	    av_close_input_file(pFormatCtx);

	    return 0;
}

