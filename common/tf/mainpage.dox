
/** \mainpage

@htmlinclude manifest.html

@b tf is a library for keeping track of coordinate frames.  There are both python binding and c++ bindings. 

 - @ref overview
 - @ref utilities
 - @ref python
 - @ref cpp
 - @ref tutorial
 - @ref faq


@page utilities tf Utilities
@section debugging_utilities  Debugging Utilities
@subsection tf_monitor tf_monitor
This node will listen to the tf_message topic and generate statistics to help diagnose problems.  

\todo WRITE ME

@subsection tf_echo tf_echo
This node will echo the latest transform between two frames.

\todo WRITE ME

@subsection viewFrames viewFrames.py
This node will generate a pdf of the current transform tree.  

\todo WRITE ME

@section helper_utilities Helper Utilites
@subsection transform_sender transform_sender
This is a command line tool to send static transforms periodically.  

\todo WRITE ME

@page overview Overview of Functionality
@section summary Summary
The tf library has a core library which keeps track of coordinate frames independent 
of ROS integration.  The library 
utilizes the Linear Math libraires from the Bullet Physics engine.  And there are 
classes which provide simple interfaces to ROS.  

The major interface to the tf library is through the tf::Transformer class.  This class
provides all the necessary external interfaces.  

However for the common use cases in a distributed ROS environment the Transformer class
is subclassed to provide automated messaging to keep up to date on transforms.  
The tf::TransformListener class will automatically listen for transform messages sent over ROS and 
insert them into the libraries storage.  There is a similar helper class the tf::TransformBroadcaster
which provides a simple interface for broadcasting transforms onto the ROS network.  

@section library Library
There is a ROS messaging independant library encompased in the tf::Transformer class.  

@subsection storage Storage
Transforms are 
expressed as a combination of a translation and rotation in 3D space, in the form of a tf::Vector3 and a 
tf::Quaternion.  Each transform has an associated frame id, parent id, and time stamp.  Each transform added
to the library is pushed into a list sorted by time for each frame id.  

@subsection lookup Transform Composition
To generate a transform between two arbitrary frames the structure of the relationship between the frames is
assumed to be a tree.  To find the spanning set between any two frames the library will start by recursively finding
the parent of both the target frame and the source frame.  These will both end at the root of the tree.  
Then the library will step back down the tree removing all but the closest common parent.  

@subsection timetransform Transforms in Time
The above transform often provides adaquate functionality to perform transforms between any two frames at the 
time the data was collected.  However often it is useful to know where an object is in relation to something 
at a different time.  However this requires knowldege of which frame the object was stationary compared to during
the time interval.  A very common example is an object observed as a vehicle is driving.  Two seconds later as the 
vehicle approaches the obstacle where the object is in relation to the vehicle is good to know.  The map or odometery 
frame use for navigation would be a good fixed frame.  However if say the vehicle had a robotic hand which grabbed the 
object.  Two seconds later the object would be in the same position with relation to the hand, and and not the vehicle, 
so the fixed frame would be hand.  And the lookup would show the position of the object in the body frame the same short 
distance from the hand as observed when picked up, but the position of the hand may have changed relative to the body in 
the two seconds, to which this would be robust.  

@subsection exceptions Exceptions
Exceptions are thrown for bad lookup requiests and malformed trees.  The exceptions all derive from tf::TransformException
which is a derivative of std::RuntimeError and have the method what() defined for debugging.  
The specific exception classes are tf::LookupException tf::MaxDepthException and tf::ConnectivityException.  

Due to the importance of timing there is also an tf::ExtrapolationException which is thrown in the case that 
the time requested is too far from data currently stored in the library.  There are two common cases when this would 
happen.  If requests are made of the transform library faster than new transforms are added it will complain.  And the 
other case if is the requested time is too far in the past to be in the list of transforms stored.  The amount of extrapolation
and how long to keep data can be set in the tf::Transformer constructor.  

@subsection computation Computation
The library does not have any built in processing.  The lists are maintained by the inserting funciton call. 
The maintenance simply prunes expired transforms from the end of the list.  All transforms are generated 
when requested.  All interfaces use the std::string form of the frame id, however when storing the transforms 
the string is mapped to a number to allow internal computations to avoid strings.  


@page cpp C++ Usage
@section usage Common Usage
For most use cases the basic library will not be used directly.  

There are two helper classes to provide sending and recieving of ROS transform
messages.  tf::TransformBroadcaster and tf::TransformListener. 

@subsection listener TransformListener
The tf::TransformListener class inherits from tf::Transformer to provide all the functionality of the 
basic library.  In addition it also provides methods to directly transform ROS messages.  
And the third part of what it does is to automatically listen for and push transforms broadcast
on ROS into the library.  

@subsection message_notifier MessageNotifier
The tf::MessageNotifier class is a very useful helper class which will subscribe to any datatype 
which has a header and only provide callbacks when transform data is available to transform the 
recieved data into the desired target frame.  This is the recommended method for recieving almost any sensor data.

@subsection broadcaster TransformBroadcaster
The tf::TransformBroadcaster class is the complement to the listener class.  The broadcaster class provides a 
simple API for broadcasting coordinate frame transforms.  

@subsection send_transform send_transform
When fixed offsets are built into the system the simplest way to add the 
transform to the system is to use the command send_transform.  It's a one
line command which will repeatedly publish the transform over ROS messages.  



@subsection datatypes Data Types used in tf
- Quaternion typedef of btQuaternion
- Vector3  typedef of btVector3
- Point  typedef of btVector3
- Transform  typedef of btTransform
- Pose  typedef of btTransform

-Stamped version of all of the above inherits from the data type and also has:
 - ros::Time stamp_
 - std::string frame_id_
 - std::string parent_frame_id_  (only used for Stamped<Transform> )

- There are analogous ROS messages in std_msgs to the Stamped data types.  

- Time represented by ros::Time and ros::Duration in ros/time.h in roscpp 


@page python Python Usage

@page faq FAQ

@section debugging Common Debugging Questions 

 - How can I see what transforms are in the system?

Use the script viewframes.py in the tf package.  Running it without 
options will listen for tfMessages for 5 seconds and produce frames.pdf
with a graph of all frames heard from.  If you're having trouble with a 
specfic node.  The optional argument "--note=NODE_NAME" 
will query an instance of TransformListener running in the node named 
NODE_NAME for what it specifically has heard.  This will allow you to see
exactly what the TransformListener node on that machine is processing.

 - I'm seeing an ExtrapolationException which is always X seconds in
the past.  Why?

A constant offset extrapolation error often is caused by a lack of
syncronization of the clocks between computers.  One computer thinks
it is ahead of the other and consequently the data recieved on a
different machine will be off consistently.  As new data comes in the
closest data will always be the same distance away resulting in the
constant ExtrapolationException.

 - What is the difference between a tf::Transform and a tf::Pose, or
for that matter a tf::Point and a tf::Vector3?  They look like the
same data type.

Think of it as the difference between time and duration.  Pose is a
specific location, like time.  You can take the difference between two
poses, and you get a transform, which is like a duration.  However,
you can't add two poses.  You can add a duration to a time and get a
time, likewise you can add a transform to a pose and get a pose.  A
Point is like Pose, while a Vector3 is like a Transform showing the
difference between two Points.  

There's also another difference in interpretation in the difference
between point and vector.  A vector subject to transformation will
only apply the rotational elements for a vector is always at the
origin.  Or another way to say it is that a vector subject to
translation is unchanged.  The same holds for a transform, but you
usually think of applying a transform to another transform, you chain
them.  The same goes for vectors.

@section faq_usage Usage Questions
 - How can tf be used in a 3D mapping framework? The
very simple example that I had in mind for the past few days was the
following: given 4 sensing devices: 1 Hokuyo, 1 SwissRanger SR4000, 1
Videre STOC and 1 Thermal FLIR camera.  The first 3 produce point
clouds, and the last 3, images. After calibration, you get the
necessary rotation matrices that you need to use to transform the
SwissRanger point cloud into the left camera on the STOC, respectively
the thermal image into left STOC, etc.  While collecting data, you
constantly need to apply these rotation matrices to the point clouds
generated by some sensors, to annotate your 3D points with texture
(RGB), thermal information, etc

This is exactly where you want to use TransformListener.  The point
cloud aggregator will be recieving messages over ROS from all of the
sensors, in their respective date types.  However for example, say the
Hokuyo is mounted on the base, and the videre is on the head and the
swiss ranger is on the left arm.  The aggregating process has no idea
where all these coordinate frames actually are in space.  However the
mechanims control process knows where the head and arms are in
relationship to the base.  And the localization process knows where
the base is in relationship to the world.  Now if they are all
publishing transforms using their own broadcaster instances.  All the
aggregator node needs to do is instantiate the TransformListener and
it will be able to relate the data from the videre to the data from
the hokuyo and data from the swiss ranger.  The TransformListener
class will extract all that information from the ROS network and
provide it automatically to the Transformer base class.  The
Transformer class then can provide the aggregator with any transform
they wish.  The goal is that the end user doesn't have to worry about
collecting any transforms, and they are automatically cached in time
and can provide interpolated or extrapolated results if desired.  The
way to make this easy for the the developer/user is the use of frame
ids.  The frame id's are simply strings which uniquely identify
coordinate frames.  When the system is operating, if you have a point
cloud arrive from the videre it will be in the "videre_camera_frame"
to use it in whatever frame you want simply transform it to the frame
id of the frame you want and use it.

 - Can I transform a Point Cloud?  

Yes it's in tf package right now it will be moving to a point cloud package soon.  

 - Can I transform a laser scan into a point cloud in a different frame?  
Yes see the laser_scan package.  

 - Would it be possible to bring back into tf a method a-la
setWithMatrix () ? Are there any disadvantages (other than re-exposing
NEWMAT) on doing that ?

I would suggest you take a look at the bullet data types.  The
btTransform can be constructed using a btQuaternion and a btVector3,
or a btMatrix and a btVector3.  And a btMatrix3x3 will take 9 values
in it's constructor. Thus you can do
tf_instance.setTransform(Stamped<tf::Transform>(tf::Transform(btMatrix3x3(1,2,3,4,5,6,7,8,9),
btVector3(x,y,z)), ros::Time().fromSec(timestamp), "frame id", "parent
id"));

 - I already have my own classes for converting to/from all 4 major
representations (euler, axis-angle, rotation matrices and
quaternions), but it would be great to use tf instead, as that makes
all these routines nicely accessible from virtually all nodes that we
want to build in ROS later.

Take a look at the bullet headers they provide all these through the
btQuaternion and btMatrix3x3 classes.

 - Is there a way to declare static transforms independent of a
specific process? Some transforms seem better suited to be defined as
parameters independent of a specific node.

There is not a way to define a static transform in tf.  This is a
design decision to make sure that log files retain relevancy.  Since
nodes can start and stop at any time they must be able to get all
necessary data starting at any time.  The parameter server could hold
this data.  However preserving the state of the parameter server
between sessions, especially when logging is complicated.  Thus the
solution we have chosen is to simply republish static transforms
periodically.  This make sure that at startup a node knows about all
transforms, and it also means that logging the topic /tf_message
captures all state of transforms making log files complete.

 - Some code (such as amcl_player.cc) refers to an expiration time for
transforms. How does the concept of transforms that expire interact
with the transform library's attempts at interpolation/extrapolation?
Is this documented anywhere?

The concept of expiring transforms is not actually supported.  What
amcl_player and a few others do is date their transforms in the
future.  This is to get around the problem that a chain of transforms
is only as current as the oldest link of the chain.  The future dating
of a transform allows the slow transform to be looked up in the
intervening period between broadcasts.  This technique is dangerous in
general, for it will cause tf to lag actual information, for tf will
assume that information is correct until it's timestamp in the future
passes.  However for transforms which change only very slowly this lag
will not be observable, which is why it is valid for amcl_player to
use this.  It can safely be used for static transforms.  I highly
recommend being careful with future dating any measurements.  Another
technique available is to allow extrapolation.  And either technique
can creep up on you and cause unusual behavior which is untraceable.

 - Can different expiration limits be set for specific transforms?
 After all, I would expect different transforms to update at rates
 that are potentially orders of magnitude different.

For the current implementation it is simply how far you future date
your data for that transform.  Remember this will cause the transform
to lag by however much you future date the values.  I do not recommend
this for any value which is expected to change at a rate more than a
slight drift correction (ala amcl_player).

 - It doesn't make sense to extrapolate some transforms (such as the
 current estimated localization offset). How do these transforms
 interact with transforms that should be interpolated/extrapolated
 when combining multiple transforms?

Our experimentation has shown that interpolation is fine, but
extrapolation almost always ends up becoming more of a problem than a
solution.  If you are having trouble with data being ready before
transforms are available I suggest using the tf::MessageNotifier class in
tf.  It will queue incoming data until transforms are available.
Having tried allowing "just a little" extrapolation, waiting for
accurate data to be available has proved a much better approach.


*/