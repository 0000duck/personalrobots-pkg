
/** \mainpage

@htmlinclude manifest.html

@b tf is a library for keeping track of coordinate frames.  There are both C++ and Python bindings. 

 - @ref overview
 - @ref utilities
 - @ref python
 - @ref cpp
 - @ref tutorial
 - @ref faq


@page utilities tf Utilities
@section debugging_utilities  Debugging Utilities
@subsection tf_monitor tf_monitor
This node will listen to the tf_message topic and generate statistics to help diagnose problems.  

\todo WRITE ME

@subsection tf_echo tf_echo
This node will echo the latest transform between two frames.

\todo WRITE ME

@subsection viewFrames viewFrames.py
This node will generate a pdf of the current transform tree.  

\todo WRITE ME

@section helper_utilities Helper Utilites
@subsection transform_sender transform_sender
This is a command line tool to send static transforms periodically.  

\todo WRITE ME

@page overview Overview of Functionality
@section summary Summary
tf is a software library that keeps track of coordinate frames. 
The main interface to the tf is through the tf::Transformer class.  This class
provides all the necessary external interfaces and can be used independently of ROS.  
For ROS integrations, there are two subclasses of tf::Transformer that assist with
receiving and publishing transforms.
The tf::TransformListener class automatically listens for transform messages sent over ROS and updates the Transformer. 
The tf::TransformBroadcaster class publishes transforms to ROS.

tf utilizes the Linear Math libraries from the Bullet Physics engine.

@section library Library
The tf::Transformer class is a ROS-indepdent library. Its design, implementation and rationale
are described below.

@subsection storage Storage
Transforms are expressed as a combination of a translation and rotation in 3D space, 
in the form of a tf::Vector3 and a tf::Quaternion.  
Each transform has an associated frame id, parent id, and time stamp.  Each transform added
to the library is pushed into a list sorted by time for each frame id.  

@subsection lookup Transform Composition
To generate a transform between two arbitrary frames, 
the structure of the relationship between the frames is assumed to be a tree.  
To find the spanning set between any two frames, tf starts by recursively finding
the parent of both the target frame and the source frame.  These will both end at the root of the tree.  
tf then steps back down the tree and removes all but the closest common parent.  

@subsection timetransform Transforms in Time
It is often useful to know where an object is in relation to something at a different time.  
This requires knowledge of which frame the object was stationary compared to during
the time interval.  
A very common example is an object observed as a vehicle is driving.  Two seconds later as the 
vehicle approaches the obstacle where the object is in relation to the vehicle is good to know.  The map or odometery 
frame use for navigation would be a good fixed frame.  However if say the vehicle had a robotic hand which grabbed the 
object.  Two seconds later the object would be in the same position with relation to the hand, and and not the vehicle, 
so the fixed frame would be hand.  And the lookup would show the position of the object in the body frame the same short 
distance from the hand as observed when picked up, but the position of the hand may have changed relative to the body in 
the two seconds, to which this would be robust.  

@subsection exceptions Exceptions
Exceptions are thrown for bad lookup requests and malformed trees.  The exceptions all derive from tf::TransformException,
which is a subclass of std::RuntimeError and have the method what() defined for debugging.  
The specific exception classes are tf::LookupException, tf::MaxDepthException and tf::ConnectivityException.  

Timing is also important to tf, so there a tf::ExtrapolationException that is thrown in cases when
the time requested is too far from data currently stored in the library.  There are two common cases when this would 
happen.  If requests are made of tf faster than new transforms are added, it will complain.  
The other case is if the requested time is too far in the past to be in the list of transforms stored.  The tf::Transformer constructor allows you to configure the amount of extrapolation
and how long to keep data.

@subsection computation Computation
tf does not do any background processing.  All transforms are generated when requested and 
transform lists are updated during the inserting function call.  Transform updates
simply prune expired transforms from the end of the list.

All interfaces use the std::string representation of the frame id, although
these strings are mapped to numerical ids interally to avoid calculations with strings.


@page cpp C++ Usage
@section usage Common Usage
For most ROS use cases, the basic tf::Transformer library is not used directly.  

There are two helper classes to provide sending and recieving of ROS transform
messages.  tf::TransformBroadcaster and tf::TransformListener. 

@subsection listener TransformListener
The tf::TransformListener class inherits from tf::Transformer to provide all the functionality of the 
basic library.  In addition, it provides methods to transform data ROS messages directly and
it automatically listens for transforms published on ROS. 

@subsection message_notifier MessageNotifier
The tf::MessageNotifier is the recommended method for receiving almost any sensor data from ROS.
Data in ROS can be published with respect to any known frame. 
The tf::MessageNotifier class makes it easy to use this data 
by providing callbacks only when it is possible to transform it into your desired 
target frame.

The tf::MessageNotifier class can subscribe to any ROS datatype that has a ROS Header.

@subsection broadcaster TransformBroadcaster
The tf::TransformBroadcaster class is the complement to the tf::TransformListener class.  The broadcaster class provides a 
simple API for broadcasting coordinate frame transforms to other ROS nodes.

@subsection send_transform send_transform
The send_transform command is the easiest way to report transforms for fixed offsets.
It is a simple command-line utility that repeatedly publishes the fixed-offset transform to ROS.

@subsection datatypes Data Types used in tf
- Quaternion typedef of btQuaternion
- Vector3  typedef of btVector3
- Point  typedef of btVector3
- Transform  typedef of btTransform
- Pose  typedef of btTransform

-Stamped version of all of the above inherits from the data type and also has:
 - ros::Time stamp_
 - std::string frame_id_
 - std::string parent_frame_id_  (only used for Stamped<Transform> )

- There are analogous ROS messages in std_msgs to the Stamped data types.  

- Time represented by ros::Time and ros::Duration in ros/time.h in roscpp 


@page python Python Usage

@page faq FAQ

@section debugging Common Debugging Questions 

 - How can I see what transforms are in the system?

Use the script viewframes.py in the tf package.  By default, it listens
to tf messages for 5 seconds and produces a pdf (frames.pdf) that graphs
all frames heard from. 
The "--node=NODE_NAME" option can assist with debugging transform issues with a
specific node.
The --node option will query the TransformListener instance in NODE_NAME
for its transform information.
This will allow you to see what that TransformListener is processing.

 - I'm seeing an ExtrapolationException which is always X seconds in
the past.  Why?

A constant offset extrapolation error is often caused by a lack of
synchronization of the clocks between computers.  One computer thinks
it is ahead of the other and consequently the data received on a
different machine will be off consistently.  As new data comes in ,the
closest data will always be the same distance away resulting in the
constant ExtrapolationException.

 - What is the difference between a tf::Transform and a tf::Pose, or
for that matter a tf::Point and a tf::Vector3?  They look like the
same data type.

Think of it as the difference between time and duration.  Pose is a
specific location, like time.  You can take the difference between two
Poses, and you get a transform, which is like a duration.  However,
you can't add two Poses.  You can add a duration to a time and get a
time, likewise you can add a transform to a Pose and get a Pose.  A
Point is like Pose, while a Vector3 is like a Transform showing the
difference between two Points.  

There's also another difference in interpretation in the difference
between point and vector.  A vector subject to transformation will
only apply the rotational elements for a vector is always at the
origin.  Or another way to say it is that a vector subject to
translation is unchanged.  The same holds for a transform, but you
usually think of applying a transform to another transform, you chain
them.  The same goes for vectors.

@section faq_usage Usage Questions
 - How can tf be used in a 3D-mapping framework? The
very simple example that I had in mind for the past few days was the
following: given 4 sensing devices: 1 Hokuyo, 1 SwissRanger SR4000, 1
Videre STOC and 1 Thermal FLIR camera.  The first 3 produce point
clouds, and the last 3, images. After calibration, you get the
necessary rotation matrices that you need to use to transform the
SwissRanger point cloud into the left camera on the STOC, respectively
the thermal image into left STOC, etc.  While collecting data, you
constantly need to apply these rotation matrices to the point clouds
generated by some sensors, to annotate your 3D points with texture
(RGB), thermal information, etc

This is exactly where you want to use tf::TransformListener.  The point
cloud aggregator will be recieving messages over ROS from all of the
sensors, in their respective date types.  However, say the
Hokuyo is mounted on the base, the Videre stereo camera is on the head, and the
swiss ranger is on the left arm.  The aggregating process has no idea
where all these coordinate frames actually are in space.  However the
mechanims control process knows where the head and arms are in
relationship to the base.  And the localization process knows where
the base is in relationship to the world.  Now if they are all
publishing transforms using their own broadcaster instances.  All the
aggregator node needs to do is instantiate the TransformListener and
it will be able to relate the data from the videre to the data from
the hokuyo and data from the swiss ranger.  The TransformListener
class will extract all that information from the ROS network and
provide it automatically to the Transformer base class.  The
Transformer class then can provide the aggregator with any transform
they wish.  The goal is that the end user doesn't have to worry about
collecting any transforms, and they are automatically cached in time
and can provide interpolated or extrapolated results if desired.  The
way to make this easy for the the developer/user is the use of frame
ids.  The frame id's are simply strings which uniquely identify
coordinate frames.  When the system is operating, if you have a point
cloud arrive from the videre it will be in the "videre_camera_frame"
to use it in whatever frame you want simply transform it to the frame
id of the frame you want and use it.

 - Can I transform a Point Cloud?  

Yes it's in tf package right now it will be moving to a point cloud package soon.  

 - Can I transform a laser scan into a point cloud in a different frame?  
Yes see the laser_scan package.  

 - Would it be possible to bring back into tf a method a-la
setWithMatrix () ? Are there any disadvantages (other than re-exposing
NEWMAT) on doing that ?

I would suggest you take a look at the bullet data types.  The
btTransform can be constructed using a btQuaternion and a btVector3,
or a btMatrix and a btVector3.  And a btMatrix3x3 will take 9 values
in it's constructor. Thus you can do
tf_instance.setTransform(Stamped<tf::Transform>(tf::Transform(btMatrix3x3(1,2,3,4,5,6,7,8,9),
btVector3(x,y,z)), ros::Time().fromSec(timestamp), "frame id", "parent
id"));

 - I already have my own classes for converting to/from all 4 major
representations (euler, axis-angle, rotation matrices and
quaternions), but it would be great to use tf instead, as that makes
all these routines nicely accessible from virtually all nodes that we
want to build in ROS later.

Take a look at the bullet headers they provide all these through the
btQuaternion and btMatrix3x3 classes.

 - Is there a way to declare static transforms independent of a
specific process? Some transforms seem better suited to be defined as
parameters independent of a specific node.

There is no way to define a static transform in tf.  This is a
design decision to make sure that log files retain relevancy.  Since
nodes can start and stop at any time, they must be able to get all
necessary data starting at any time.  The ROS Parameter Server could hold
this data.  However, preserving the state of the Parameter Server
between sessions, especially when logging, is complicated.  Thus, the
solution we have chosen is to simply republish static transforms
periodically.  This make sure that at startup a node knows about all
transforms, and it also means that logging the topic /tf_message
captures all state of transforms making log files complete.

 - Some code (such as amcl_player.cc) refers to an expiration time for
transforms. How does the concept of transforms that expire interact
with the transform library's attempts at interpolation/extrapolation?
Is this documented anywhere?

The concept of expiring transforms is not actually supported.  What
amcl_player and a few others do is date their transforms in the
future.  This is to get around the problem that a chain of transforms
is only as current as the oldest link of the chain.  The future dating
of a transform allows the slow transform to be looked up in the
intervening period between broadcasts.  This technique is dangerous in
general, for it will cause tf to lag actual information, for tf will
assume that information is correct until it's timestamp in the future
passes.  However for transforms which change only very slowly this lag
will not be observable, which is why it is valid for amcl_player to
use this.  It can safely be used for static transforms.  I highly
recommend being careful with future dating any measurements.  Another
technique available is to allow extrapolation.  And either technique
can creep up on you and cause unusual behavior which is untraceable.

 - Can different expiration limits be set for specific transforms?
 After all, I would expect different transforms to update at rates
 that are potentially orders of magnitude different.

For the current implementation, it is simply how far you future date
your data for that transform.  Remember, this will cause the transform
to lag by however much you future date the values.  I do not recommend
this for any value which is expected to change at a rate more than a
slight drift correction (ala amcl_player).

 - It doesn't make sense to extrapolate some transforms (such as the
 current estimated localization offset). How do these transforms
 interact with transforms that should be interpolated/extrapolated
 when combining multiple transforms?

Our experimentation has shown that interpolation is fine, but
extrapolation almost always ends up becoming more of a problem than a
solution.  If you are having trouble with data being ready before
transforms are available I suggest using the tf::MessageNotifier class in
tf.  It will queue incoming data until transforms are available.
Having tried allowing "just a little" extrapolation, waiting for
accurate data to be available has proved a much better approach.


*/
